{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import pywt\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "import scipy.io as sio \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    data_path = os.path.join(os.getcwd(),'/media/dy113/disk1/Project_xjr/dataset')\n",
    "    if name == 'IP':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'IndianPines/Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'IndianPines/Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "    elif name == 'SA':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Salinas/Salinas_corrected.mat'))['salinas_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Salinas/Salinas_gt.mat'))['salinas_gt']\n",
    "    elif name == 'PU':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'PaviaU/PaviaU.mat'))['paviaU']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU/PaviaU_gt.mat'))['paviaU_gt']\n",
    "    elif name == 'KSC':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'KSC/KSC.mat'))['KSC']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'KSC/KSC_gt.mat'))['KSC_gt']\n",
    "    elif name == 'DISPU':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'DISPU/PUtrain_gt.mat'))['PU_tgt']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU/PaviaU_gt.mat'))['paviaU_gt']\n",
    "    elif name == 'Houston':\n",
    "        data = sio.loadmat(os.path.join(data_path, '2013_DFTC/huston2013/Houston.mat'))['Houston']\n",
    "        labels = sio.loadmat(os.path.join(data_path, '2013_DFTC/huston2013/Houston_gt.mat'))['Houston_gt']\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padWithZeros(X,margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2 * margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX\n",
    "\n",
    "def createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n",
    "    # 给 X 做 padding\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels\n",
    "\n",
    "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(145, 145, 200)\n",
      "(145, 145)\n",
      "Hyperspectral data shape:  (145, 145, 200)\n",
      "Label shape:  (145, 145)\n",
      "Band nums:  200\n"
     ]
    }
   ],
   "source": [
    "class_num = 16\n",
    "dataset = 'IP'\n",
    "batchsize = 128\n",
    "X, y = loadData(dataset)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "test_ratio = 0.90\n",
    "patch_size = 15\n",
    "band_nums = X.shape[2]\n",
    "pca_components = 30\n",
    "\n",
    "print('Hyperspectral data shape: ', X.shape)\n",
    "print('Label shape: ',y.shape)\n",
    "print('Band nums: ', X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyPCA(X, numComponents):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=numComponents, whiten=True)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX,(X.shape[0],X.shape[1],numComponents))\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after PCA:  (145, 145, 30)\n",
      "Data cube X shape:  (10249, 15, 15, 30)\n",
      "Data cube y shape:  (10249,)\n",
      "30\n",
      "Xtrain shape:  (1024, 15, 15, 30)\n",
      "Xtest shape:  (9225, 15, 15, 30)\n",
      "ytrain shape:  (1024,)\n",
      "ytest shape:  (9225,)\n",
      "before transpose: Xtrain shape:  (1024, 15, 15, 30, 1)\n",
      "before transpose: Xtest  shape:  (9225, 15, 15, 30, 1)\n",
      "after transpose: Xtrain shape:  (1024, 1, 15, 15, 30)\n",
      "after transpose: Xtest  shape:  (9225, 1, 15, 15, 30)\n"
     ]
    }
   ],
   "source": [
    "X_pca = applyPCA(X,numComponents=pca_components)\n",
    "print('Data shape after PCA: ',X_pca.shape)\n",
    "\n",
    "X_pca,y = createImageCubes(X_pca,y,windowSize=patch_size)\n",
    "print('Data cube X shape: ', X_pca.shape)\n",
    "print('Data cube y shape: ', y.shape)\n",
    "\n",
    "\n",
    "# X,y = createImageCubes(X,y,windowSize=patch_size)\n",
    "# print('Data cube X shape: ', X.shape)\n",
    "# print('Data cube y shape: ', y.shape)\n",
    "\n",
    "dim3=X_pca.shape[3]\n",
    "print(dim3)\n",
    "band_nums = dim3\n",
    "\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X_pca, y, test_ratio)\n",
    "# Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, y, test_ratio)\n",
    "print('Xtrain shape: ',Xtrain.shape)\n",
    "print('Xtest shape: ',Xtest.shape)\n",
    "print('ytrain shape: ',ytrain.shape)\n",
    "print('ytest shape: ',ytest.shape)\n",
    "\n",
    "Xtrain = Xtrain.reshape(-1, patch_size, patch_size, Xtrain.shape[3], 1)\n",
    "Xtest  = Xtest.reshape(-1, patch_size, patch_size, Xtrain.shape[3], 1)\n",
    "print('before transpose: Xtrain shape: ', Xtrain.shape)\n",
    "print('before transpose: Xtest  shape: ', Xtest.shape)\n",
    "\n",
    "# Xtrain = Xtrain.transpose(0, 4, 3, 2, 1)\n",
    "# Xtest  = Xtest.transpose(0, 4, 3, 2, 1)\n",
    "Xtrain = Xtrain.transpose(0, 4, 2, 1, 3)\n",
    "Xtest  = Xtest.transpose(0, 4, 2, 1, 3)\n",
    "print('after transpose: Xtrain shape: ', Xtrain.shape)\n",
    "print('after transpose: Xtest  shape: ', Xtest.shape)\n",
    "\n",
    "\n",
    "# Xtrain = Xtrain.transpose(0, 3, 1, 2)\n",
    "# Xtest  = Xtest.transpose(0, 3, 1, 2)\n",
    "# print('after transpose: Xtrain shape: ', Xtrain.shape)\n",
    "# print('after transpose: Xtest  shape: ', Xtest.shape)\n",
    "\n",
    "\n",
    "\n",
    "class TrainDS(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.len = Xtrain.shape[0]\n",
    "        self.x_data = torch.FloatTensor(Xtrain)\n",
    "        self.y_data = torch.LongTensor(ytrain)\n",
    "    def __getitem__(self, index):\n",
    "        # 根据索引返回数据和对应的标签\n",
    "        return self.x_data[index], self.y_data[index] \n",
    "    def __len__(self):\n",
    "        # 返回文件数据的数目\n",
    "        return self.len\n",
    "\n",
    "\n",
    "class TestDS(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.len = Xtest.shape[0]\n",
    "        self.x_data = torch.FloatTensor(Xtest)\n",
    "        self.y_data = torch.LongTensor(ytest)\n",
    "    def __getitem__(self, index):\n",
    "        # 根据索引返回数据和对应的标签\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    def __len__(self):\n",
    "        # 返回文件数据的数目\n",
    "        return self.len\n",
    "      \n",
    "\n",
    "trainset = TrainDS()\n",
    "testset  = TestDS()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "test_loader  = torch.utils.data.DataLoader(dataset=testset,  batch_size=batchsize, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wavelet(nn.Module):\n",
    "    \"\"\"This module extract wavelet coefficient defined in pywt\n",
    "    and create 3D convolution kernels to be able to use GPU\"\"\"\n",
    "\n",
    "    def _coef_h(self, in_planes, coef):\n",
    "        \"\"\"Construct the weight matrix for horizontal 3D convolution.\n",
    "        The weights are repeated on the diagonal\"\"\"\n",
    "        v = []\n",
    "        for i in range(in_planes):\n",
    "            l = []\n",
    "            for j in range(in_planes):\n",
    "                if i == j:\n",
    "                    l.append([[[c for c in coef]]])\n",
    "                else:\n",
    "                    l.append([[[0.0 for c in coef]]])\n",
    "            v.append(l)\n",
    "#         print(v)\n",
    "        return v\n",
    "\n",
    "    def _coef_v(self, in_planes, coef):\n",
    "        \"\"\"Construct the weight matrix for vertical 3D convolution.\n",
    "        The weights are repeated on the diagonal\"\"\"\n",
    "        v = []\n",
    "        for i in range(in_planes):\n",
    "            l = []\n",
    "            for j in range(in_planes):\n",
    "                if i == j:\n",
    "                    l.append([[[c] for c in coef]])\n",
    "                else:\n",
    "                    l.append([[[0.0] for c in coef]])\n",
    "            v.append(l)\n",
    "#         print(v)\n",
    "        return v\n",
    "\n",
    "    def _coef_d(self, in_planes, coef):\n",
    "        \"\"\"Construct the weight matrix for depth 3D convolution.\n",
    "        The weights are repeated on the diagonal\"\"\"\n",
    "        v = []\n",
    "        for i in range(in_planes):\n",
    "            l = []\n",
    "            for j in range(in_planes):\n",
    "                if i == j:\n",
    "                    l.append([[[c]] for c in coef])\n",
    "                else:\n",
    "                    l.append([[[0.0]] for c in coef])\n",
    "            v.append(l)\n",
    "#         print(v)\n",
    "        return v\n",
    "    \n",
    "    def __init__(self, in_planes, horizontal, vertical, name=\"db2\"):\n",
    "        super(Wavelet, self).__init__()\n",
    "\n",
    "        # Import wavelet coefficients\n",
    "        import pywt\n",
    "        wavelet = pywt.Wavelet(name)\n",
    "        coef_low = wavelet.dec_lo\n",
    "        coef_high = wavelet.dec_hi\n",
    "        # Determine the kernel 3D shape\n",
    "        nb_coeff = len(coef_low)\n",
    "        # print(nb_coeff)\n",
    "\n",
    "        if horizontal & (not vertical):\n",
    "            kernel_size = (1, 1, nb_coeff)\n",
    "            # stride = (1, 1, 2)\n",
    "            stride = (1, 1, 1)\n",
    "            pad = (nb_coeff // 2, nb_coeff - 1 - nb_coeff // 2, 0, 0, 0, 0)\n",
    "            weights_low = self._coef_h(in_planes, coef_low)\n",
    "            weights_high = self._coef_h(in_planes, coef_high)\n",
    "\n",
    "        elif (not horizontal) & vertical:\n",
    "            kernel_size = (1, nb_coeff, 1)\n",
    "            # stride = (1, 2, 1)\n",
    "            stride = (1, 1, 1)\n",
    "            pad = (0, 0, nb_coeff // 2, nb_coeff - 1 - nb_coeff // 2, 0, 0)\n",
    "            weights_low = self._coef_v(in_planes, coef_low)\n",
    "            weights_high = self._coef_v(in_planes, coef_high)\n",
    "\n",
    "        elif (not horizontal) & (not vertical):\n",
    "            kernel_size = (nb_coeff, 1, 1)\n",
    "            # stride = (2, 1, 1)\n",
    "            stride = (1, 1, 1)\n",
    "            pad = (0, 0, 0, 0, nb_coeff // 2, nb_coeff - 1 - nb_coeff // 2)\n",
    "            weights_low = self._coef_d(in_planes, coef_low)\n",
    "            weights_high = self._coef_d(in_planes, coef_high)\n",
    "           \n",
    "        # Create the conv2D\n",
    "        self.conv_high = nn.Conv3d(\n",
    "            in_planes, in_planes, kernel_size=kernel_size, stride=stride, bias=False)\n",
    "        self.conv_low = nn.Conv3d(\n",
    "            in_planes, in_planes, kernel_size=kernel_size, stride=stride, bias=False)\n",
    "        self.padding = nn.ReplicationPad3d(padding=pad)\n",
    "\n",
    "        # Replace their weights\n",
    "        self.conv_high.weight = torch.nn.Parameter(\n",
    "            data=torch.Tensor(weights_high), requires_grad=False)\n",
    "        self.conv_low.weight = torch.nn.Parameter(\n",
    "            data=torch.Tensor(weights_low), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Returns the approximation and detail part'''\n",
    "        x = self.padding(x)\n",
    "        return (self.conv_low(x), self.conv_high(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wavelet3D(nn.Module):\n",
    "    def __init__(self, in_planes, name=\"db2\"):\n",
    "        super(Wavelet3D, self).__init__()\n",
    "        self.horizontal_wavelet = Wavelet(in_planes, horizontal=True, vertical=False, name=name)\n",
    "        self.vertical_wavelet = Wavelet(in_planes, horizontal=False, vertical=True,  name=name)\n",
    "        self.depth_wavelet = Wavelet(in_planes, horizontal=False, vertical=False,  name=name)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Returns (LL, LH, HL, HH)'''\n",
    "        (c, d) = self.horizontal_wavelet(x)\n",
    "        #print('H',c.size(),d.size())\n",
    "        (LL, LH) = self.vertical_wavelet(c)\n",
    "        #print('V',LL.size(),LH.size())\n",
    "        (HL, HH) = self.vertical_wavelet(d)\n",
    "        (LLL, LLH) = self.depth_wavelet(LL)\n",
    "        #print('D',LLL.size(),LLH.size())\n",
    "        (LHL, LHH) = self.depth_wavelet(LH)\n",
    "        (HLL, HLH) = self.depth_wavelet(HL)\n",
    "        (HHL, HHH) = self.depth_wavelet(HH)\n",
    "        return (LLL, LLH, LHL, LHH, HLL, HLH, HHL, HHH)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class waveblock(nn.Module):\n",
    "    def __init__(self, in_planes, name):\n",
    "        super(waveblock, self).__init__()\n",
    "        self.wavelet3d = Wavelet3D(in_planes,name=name)\n",
    "\n",
    "    def forward(self,x):\n",
    "        (LLL, LLH, LHL, LHH, HLL, HLH, HHL, HHH) = self.wavelet3d(x)\n",
    "        x = LLL\n",
    "        details = torch.cat([LLH, LHL, LHH, HLL, HLH, HHL, HHH],1)\n",
    "        return x,details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConvBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size,stride,padding=0):\n",
    "        super(BasicConvBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm3d(out_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)    \n",
    "        self.conv1 = nn.Conv3d(in_planes,out_planes,kernel_size, stride=stride,\n",
    "                               padding=padding, bias=False)\n",
    "                   \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn1(self.conv1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConvBlock2D(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size,stride,padding=0):\n",
    "        super(BasicConvBlock2D, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes,kernel_size, stride=stride,\n",
    "                               padding=padding, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn1(self.conv1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveCnntest(nn.Module):\n",
    "    def __init__(self, num_classes,band_nums,patch_size):\n",
    "        super(WaveCnntest, self).__init__() \n",
    "        # self.conv1 = BasicConvBlock2D(band_nums,patch_size,1,1,0)\n",
    "\n",
    "        self.conv00 = BasicConvBlock(1,15,(1,1,5),(1,1,5),0)\n",
    "        self.conv01 = BasicConvBlock(15,15,(1,1,20),(1,1,1),0)\n",
    "        self.conv02 = BasicConvBlock(1,patch_size,(1,1,band_nums),(1,1,1),0)\n",
    "\n",
    "        self.wave1 = waveblock(1, name=\"db1\")    \n",
    "        self.wave2 = waveblock(1, name=\"db2\")\n",
    "\n",
    "        self.conv1 = BasicConvBlock(8,8,3,1,1)\n",
    "        self.conv2 = BasicConvBlock(1,8,3,1,1)\n",
    "\n",
    "        # self.conv3 = BasicConvBlock(32,32,3,1,1)\n",
    "                \n",
    "#         # bottleneck layer        \n",
    "        self.conv3 = nn.Sequential(\n",
    "                        BasicConvBlock(1,16,3,1),\n",
    "                        BasicConvBlock(16,8,3,1))\n",
    "        \n",
    "        self.pool = nn.MaxPool3d(kernel_size=2,stride=2)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x = self.conv00(x)\n",
    "        # # print(x.shape)\n",
    "        # # b=x.shape[4]\n",
    "        # # print(b)\n",
    "        # x = self.conv01(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.conv02(x)\n",
    "        x = x.reshape(x.shape[0],1,x.shape[1],x.shape[1],x.shape[1]) \n",
    "\n",
    "        # x = self.conv01(x)\n",
    "        # x = self.conv02(x)\n",
    "        # x = x.unsqueeze(1)\n",
    "        # # x = x.permute(0,1,3,4,2)\n",
    "\n",
    "        # app1, det1 = self.wave1(x)\n",
    "        # wave1 = torch.cat([app1, det1],1)\n",
    "        # x11 = self.conv1(wave1)\n",
    "\n",
    "        # x11 = self.conv2(x)\n",
    "        # # x11 = self.conv1(x11)\n",
    "\n",
    "        # x1 = self.conv2(x)          \n",
    "        # x2 = torch.cat([x1, x11],1)\n",
    "\n",
    "        x2 = x\n",
    "        \n",
    "        x3 = self.conv3(x2)        \n",
    "        # x3 = self.conv4(x2)\n",
    "        x3 = self.pool(x3)       \n",
    "\n",
    "        x3 = x3.reshape(x3.shape[0],-1)\n",
    "                       \n",
    "\n",
    "#         app2, det2 = self.wave2(app1)\n",
    "#         wave2 = torch.cat([app2, det2],1)\n",
    "             \n",
    "#         x2 = self.conv3(wave2)        \n",
    "#         x2 = torch.cat([wave2,x2,x1],1)  \n",
    "        \n",
    "#         x2 = self.conv4(x2)\n",
    "#         x2 = x2.reshape(x2.shape[0],-1)\n",
    "      \n",
    "#         app2, det2 = self.wave2(app1)\n",
    "#         wave2 = torch.cat([app2, det2],1)\n",
    "#         x2 = self.conv2(wave2)\n",
    "        \n",
    "#         app3, det3 = self.wave3(app2)\n",
    "#         wave3 = torch.cat([app3, det3],1)\n",
    "#         x3 = self.conv2(wave3)\n",
    "               \n",
    "#         app4, det4 = self.wave3(app3)\n",
    "#         wave4 = torch.cat([app4, det4],1)\n",
    "#         x4 = self.conv2(wave4)\n",
    "                            \n",
    "#         x4 = torch.cat([wave1,x1,wave2,x2,wave3,x3,wave4,x4],1)    \n",
    "# #         print(x3.shape)\n",
    "#         x4 = self.conv3(x4)\n",
    "# #         x3 = self.pool(x3)\n",
    "#         x4 = x4.reshape(x4.shape[0],-1)\n",
    "# #         flat = x3.shape[1]  \n",
    "# #         print(flat)\n",
    "        \n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res torch.Size([1024, 1000])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     input = torch.randn(1024,band_nums,patch_size, patch_size)\n",
    "#     input = torch.randn(1, 3, 15, 15, 15)\n",
    "    # input = torch.randn(1024,1,patch_size, patch_size,pca_components)\n",
    "    input = torch.randn(1024,1,patch_size, patch_size,dim3)\n",
    "    m_net = WaveCnntest(class_num,band_nums,patch_size)\n",
    "    res = m_net(input)\n",
    "    print('res',res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveCnn(nn.Module):\n",
    "    def __init__(self, num_classes,band_nums,patch_size):\n",
    "        super(WaveCnn, self).__init__()  \n",
    "        # self.conv1 = BasicConvBlock2D(band_nums,patch_size,1,1,0)\n",
    "        \n",
    "        # self.conv0 = BasicConvBlock(1,1,(1,1,5),(1,1,2),1)\n",
    "        # self.conv01 = BasicConvBlock(1,1,(1,1,5),(1,1,2),1)\n",
    "        # self.conv02 = BasicConvBlock(1,1,(1,1,5),(1,1,2),1)\n",
    "\n",
    "       # self.conv0 = BasicConvBlock(1,1,(1,1,5),(1,1,5),0)\n",
    "        self.conv00 = BasicConvBlock(1,15,(1,1,7),(1,1,5),(0,0,1))\n",
    "        self.conv01 = BasicConvBlock(15,15,(1,1,20),(1,1,1),0)\n",
    "        # self.conv02 = BasicConvBlock(15,15,(1,1,5),(1,1,),1)\n",
    "        self.conv02 = BasicConvBlock(1,patch_size,(1,1,band_nums),(1,1,1),0)\n",
    "\n",
    "        self.wave1 = waveblock(1, name=\"db2\")    \n",
    "#         self.wave2 = waveblock(1, name=\"db2\")\n",
    "#         self.wave3 = waveblock(1, name=\"db2\")\n",
    "\n",
    "        self.conv1 = BasicConvBlock(8,8,3,1,1)\n",
    "        self.conv2 = BasicConvBlock(1,8,3,1,1)\n",
    "\n",
    "        # self.conv3 = BasicConvBlock(32,32,3,1,1)\n",
    "                \n",
    "#         # bottleneck layer        \n",
    "        # self.conv3 = nn.Sequential(\n",
    "        #                 BasicConvBlock(1,16,3,1),\n",
    "        #                 BasicConvBlock(16,8,3,1))\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "                        BasicConvBlock(1,16,3,1),\n",
    "                        BasicConvBlock(16,8,3,1))\n",
    "        \n",
    "        self.pool = nn.MaxPool3d(kernel_size=2,stride=2)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "                            # nn.Linear(1536,256),\n",
    "                            nn.Linear(1000,256),\n",
    "                            # nn.Linear(1280,256),\n",
    "                            nn.Dropout(p=0.4),\n",
    "                            nn.ReLU(inplace = True),\n",
    "                            nn.Linear(256,128),\n",
    "                            nn.Dropout(p=0.4),\n",
    "                            nn.ReLU(inplace = True),\n",
    "#                             nn.Linear(10648,num_classes),\n",
    "#                             nn.Linear(74088,num_classes),\n",
    "#                             nn.Linear(10648,num_classes),\n",
    "                            nn.Linear(128,num_classes),\n",
    "                            nn.Dropout(p=0.4))                     \n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x = self.conv00(x)\n",
    "        # x = self.conv01(x)\n",
    "        # # print(x.shape)\n",
    "\n",
    "        x = self.conv02(x)\n",
    "        x = x.reshape(x.shape[0],1,x.shape[1],x.shape[1],x.shape[1])   \n",
    "        # x = self.conv01(x)\n",
    "        # x = self.conv02(x)\n",
    "        # x = x.unsqueeze(1)\n",
    "        # # x = x.permute(0,1,3,4,2)\n",
    "\n",
    "        # app1, det1 = self.wave1(x)\n",
    "        # wave1 = torch.cat([app1, det1],1)\n",
    "        # x11 = self.conv1(wave1)\n",
    "\n",
    "        # x11 = self.conv2(x)\n",
    "        # # x11 = self.conv1(x11)\n",
    "\n",
    "        # x1 = self.conv2(x)          \n",
    "        # x2 = torch.cat([x1, x11],1)\n",
    "\n",
    "        x2 = x\n",
    "\n",
    "        x3 = self.conv3(x2)        \n",
    "        # x3 = self.conv4(x2)\n",
    "        x3 = self.pool(x3)       \n",
    "\n",
    "        x3 = x3.reshape(x3.shape[0],-1)\n",
    "                       \n",
    "\n",
    "        out = self.classifier(x3)     \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res torch.Size([1024, 16])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # input = torch.randn(1024,1,patch_size, patch_size,pca_components)\n",
    "    input = torch.randn(1024,1,patch_size, patch_size,dim3)\n",
    "    m_net = WaveCnn(class_num,band_nums,patch_size)\n",
    "    res = m_net(input)\n",
    "    print('res',res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# modelsum = WaveCnn(class_num,band_nums,patch_size).to(device)\n",
    "# # print(modelsum)\n",
    "# summary(modelsum,(1,patch_size,patch_size,pca_components))\n",
    "# # summary(modelsum,(1,patch_size,patch_size,dim3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1]   [loss avg: 21.625247]   [current loss: 2.610290]\n",
      "Validation loss decreased (inf --> 2.610290).  Saving model ...\n",
      "[Epoch: 2]   [loss avg: 20.936342]   [current loss: 2.520528]\n",
      "Validation loss decreased (2.610290 --> 2.520528).  Saving model ...\n",
      "[Epoch: 3]   [loss avg: 20.559311]   [current loss: 2.443254]\n",
      "Validation loss decreased (2.520528 --> 2.443254).  Saving model ...\n",
      "[Epoch: 4]   [loss avg: 20.098880]   [current loss: 2.221057]\n",
      "Validation loss decreased (2.443254 --> 2.221057).  Saving model ...\n",
      "[Epoch: 5]   [loss avg: 19.655518]   [current loss: 2.304279]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 6]   [loss avg: 19.282576]   [current loss: 2.142871]\n",
      "Validation loss decreased (2.221057 --> 2.142871).  Saving model ...\n",
      "[Epoch: 7]   [loss avg: 18.818158]   [current loss: 2.042007]\n",
      "Validation loss decreased (2.142871 --> 2.042007).  Saving model ...\n",
      "[Epoch: 8]   [loss avg: 18.401139]   [current loss: 1.931168]\n",
      "Validation loss decreased (2.042007 --> 1.931168).  Saving model ...\n",
      "[Epoch: 9]   [loss avg: 18.055689]   [current loss: 1.953785]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 10]   [loss avg: 17.644290]   [current loss: 1.710434]\n",
      "Validation loss decreased (1.931168 --> 1.710434).  Saving model ...\n",
      "[Epoch: 11]   [loss avg: 17.292954]   [current loss: 1.676492]\n",
      "Validation loss decreased (1.710434 --> 1.676492).  Saving model ...\n",
      "[Epoch: 12]   [loss avg: 16.991429]   [current loss: 1.648867]\n",
      "Validation loss decreased (1.676492 --> 1.648867).  Saving model ...\n",
      "[Epoch: 13]   [loss avg: 16.686015]   [current loss: 1.551867]\n",
      "Validation loss decreased (1.648867 --> 1.551867).  Saving model ...\n",
      "[Epoch: 14]   [loss avg: 16.378653]   [current loss: 1.468534]\n",
      "Validation loss decreased (1.551867 --> 1.468534).  Saving model ...\n",
      "[Epoch: 15]   [loss avg: 16.084556]   [current loss: 1.303708]\n",
      "Validation loss decreased (1.468534 --> 1.303708).  Saving model ...\n",
      "[Epoch: 16]   [loss avg: 15.790387]   [current loss: 1.487876]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 17]   [loss avg: 15.512414]   [current loss: 1.307333]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 18]   [loss avg: 15.223999]   [current loss: 1.384277]\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[Epoch: 19]   [loss avg: 14.964101]   [current loss: 1.215280]\n",
      "Validation loss decreased (1.303708 --> 1.215280).  Saving model ...\n",
      "[Epoch: 20]   [loss avg: 14.724371]   [current loss: 1.219464]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 21]   [loss avg: 14.487757]   [current loss: 1.336573]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 22]   [loss avg: 14.252780]   [current loss: 1.232195]\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[Epoch: 23]   [loss avg: 14.044201]   [current loss: 1.242755]\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[Epoch: 24]   [loss avg: 13.815251]   [current loss: 1.033502]\n",
      "Validation loss decreased (1.215280 --> 1.033502).  Saving model ...\n",
      "[Epoch: 25]   [loss avg: 13.600214]   [current loss: 1.071727]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 26]   [loss avg: 13.403412]   [current loss: 1.108056]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 27]   [loss avg: 13.210378]   [current loss: 0.931479]\n",
      "Validation loss decreased (1.033502 --> 0.931479).  Saving model ...\n",
      "[Epoch: 28]   [loss avg: 13.008088]   [current loss: 0.966320]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 29]   [loss avg: 12.833049]   [current loss: 0.975556]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 30]   [loss avg: 12.669162]   [current loss: 1.016382]\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[Epoch: 31]   [loss avg: 12.511465]   [current loss: 1.033047]\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[Epoch: 32]   [loss avg: 12.354137]   [current loss: 0.857179]\n",
      "Validation loss decreased (0.931479 --> 0.857179).  Saving model ...\n",
      "[Epoch: 33]   [loss avg: 12.200496]   [current loss: 0.931681]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 34]   [loss avg: 12.051277]   [current loss: 0.850475]\n",
      "Validation loss decreased (0.857179 --> 0.850475).  Saving model ...\n",
      "[Epoch: 35]   [loss avg: 11.909687]   [current loss: 0.934897]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 36]   [loss avg: 11.783823]   [current loss: 0.942244]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 37]   [loss avg: 11.659754]   [current loss: 0.886400]\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[Epoch: 38]   [loss avg: 11.542996]   [current loss: 0.764759]\n",
      "Validation loss decreased (0.850475 --> 0.764759).  Saving model ...\n",
      "[Epoch: 39]   [loss avg: 11.423501]   [current loss: 0.692600]\n",
      "Validation loss decreased (0.764759 --> 0.692600).  Saving model ...\n",
      "[Epoch: 40]   [loss avg: 11.311951]   [current loss: 0.814494]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 41]   [loss avg: 11.214110]   [current loss: 0.880849]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 42]   [loss avg: 11.106400]   [current loss: 0.713380]\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[Epoch: 43]   [loss avg: 11.003693]   [current loss: 0.876968]\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[Epoch: 44]   [loss avg: 10.911911]   [current loss: 0.945871]\n",
      "EarlyStopping counter: 5 out of 30\n",
      "[Epoch: 45]   [loss avg: 10.836410]   [current loss: 1.053395]\n",
      "EarlyStopping counter: 6 out of 30\n",
      "[Epoch: 46]   [loss avg: 10.748740]   [current loss: 0.788604]\n",
      "EarlyStopping counter: 7 out of 30\n",
      "[Epoch: 47]   [loss avg: 10.656230]   [current loss: 0.781727]\n",
      "EarlyStopping counter: 8 out of 30\n",
      "[Epoch: 48]   [loss avg: 10.569365]   [current loss: 0.788511]\n",
      "EarlyStopping counter: 9 out of 30\n",
      "[Epoch: 49]   [loss avg: 10.488153]   [current loss: 0.808370]\n",
      "EarlyStopping counter: 10 out of 30\n",
      "[Epoch: 50]   [loss avg: 10.415528]   [current loss: 0.802566]\n",
      "EarlyStopping counter: 11 out of 30\n",
      "[Epoch: 51]   [loss avg: 10.336188]   [current loss: 0.917502]\n",
      "EarlyStopping counter: 12 out of 30\n",
      "[Epoch: 52]   [loss avg: 10.257267]   [current loss: 0.690313]\n",
      "Validation loss decreased (0.692600 --> 0.690313).  Saving model ...\n",
      "[Epoch: 53]   [loss avg: 10.196220]   [current loss: 0.786900]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 54]   [loss avg: 10.139530]   [current loss: 0.904254]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 55]   [loss avg: 10.080167]   [current loss: 0.816643]\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[Epoch: 56]   [loss avg: 10.020364]   [current loss: 0.944394]\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[Epoch: 57]   [loss avg: 9.964435]   [current loss: 0.775927]\n",
      "EarlyStopping counter: 5 out of 30\n",
      "[Epoch: 58]   [loss avg: 9.906109]   [current loss: 0.704104]\n",
      "EarlyStopping counter: 6 out of 30\n",
      "[Epoch: 59]   [loss avg: 9.847010]   [current loss: 0.890021]\n",
      "EarlyStopping counter: 7 out of 30\n",
      "[Epoch: 60]   [loss avg: 9.794603]   [current loss: 0.668613]\n",
      "Validation loss decreased (0.690313 --> 0.668613).  Saving model ...\n",
      "[Epoch: 61]   [loss avg: 9.743884]   [current loss: 0.821324]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 62]   [loss avg: 9.689780]   [current loss: 0.866390]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 63]   [loss avg: 9.631560]   [current loss: 0.754311]\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[Epoch: 64]   [loss avg: 9.581287]   [current loss: 0.873743]\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[Epoch: 65]   [loss avg: 9.536148]   [current loss: 0.837686]\n",
      "EarlyStopping counter: 5 out of 30\n",
      "[Epoch: 66]   [loss avg: 9.492887]   [current loss: 0.858172]\n",
      "EarlyStopping counter: 6 out of 30\n",
      "[Epoch: 67]   [loss avg: 9.437484]   [current loss: 0.721562]\n",
      "EarlyStopping counter: 7 out of 30\n",
      "[Epoch: 68]   [loss avg: 9.395958]   [current loss: 0.860472]\n",
      "EarlyStopping counter: 8 out of 30\n",
      "[Epoch: 69]   [loss avg: 9.354643]   [current loss: 0.784663]\n",
      "EarlyStopping counter: 9 out of 30\n",
      "[Epoch: 70]   [loss avg: 9.310688]   [current loss: 0.787649]\n",
      "EarlyStopping counter: 10 out of 30\n",
      "[Epoch: 71]   [loss avg: 9.267438]   [current loss: 0.737592]\n",
      "EarlyStopping counter: 11 out of 30\n",
      "[Epoch: 72]   [loss avg: 9.230811]   [current loss: 0.824931]\n",
      "EarlyStopping counter: 12 out of 30\n",
      "[Epoch: 73]   [loss avg: 9.192434]   [current loss: 0.697769]\n",
      "EarlyStopping counter: 13 out of 30\n",
      "[Epoch: 74]   [loss avg: 9.155506]   [current loss: 0.817885]\n",
      "EarlyStopping counter: 14 out of 30\n",
      "[Epoch: 75]   [loss avg: 9.119159]   [current loss: 0.765838]\n",
      "EarlyStopping counter: 15 out of 30\n",
      "[Epoch: 76]   [loss avg: 9.084148]   [current loss: 0.990100]\n",
      "EarlyStopping counter: 16 out of 30\n",
      "[Epoch: 77]   [loss avg: 9.060014]   [current loss: 0.936252]\n",
      "EarlyStopping counter: 17 out of 30\n",
      "[Epoch: 78]   [loss avg: 9.022657]   [current loss: 0.779381]\n",
      "EarlyStopping counter: 18 out of 30\n",
      "[Epoch: 79]   [loss avg: 8.994402]   [current loss: 0.683065]\n",
      "EarlyStopping counter: 19 out of 30\n",
      "[Epoch: 80]   [loss avg: 8.960302]   [current loss: 0.804650]\n",
      "EarlyStopping counter: 20 out of 30\n",
      "[Epoch: 81]   [loss avg: 8.930294]   [current loss: 0.847637]\n",
      "EarlyStopping counter: 21 out of 30\n",
      "[Epoch: 82]   [loss avg: 8.894336]   [current loss: 0.547663]\n",
      "Validation loss decreased (0.668613 --> 0.547663).  Saving model ...\n",
      "[Epoch: 83]   [loss avg: 8.866666]   [current loss: 0.731103]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 84]   [loss avg: 8.835382]   [current loss: 0.906913]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 85]   [loss avg: 8.806586]   [current loss: 0.748564]\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[Epoch: 86]   [loss avg: 8.777868]   [current loss: 0.865635]\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[Epoch: 87]   [loss avg: 8.751250]   [current loss: 0.817260]\n",
      "EarlyStopping counter: 5 out of 30\n",
      "[Epoch: 88]   [loss avg: 8.721781]   [current loss: 0.709969]\n",
      "EarlyStopping counter: 6 out of 30\n",
      "[Epoch: 89]   [loss avg: 8.697981]   [current loss: 0.767120]\n",
      "EarlyStopping counter: 7 out of 30\n",
      "[Epoch: 90]   [loss avg: 8.671359]   [current loss: 0.813347]\n",
      "EarlyStopping counter: 8 out of 30\n",
      "[Epoch: 91]   [loss avg: 8.651477]   [current loss: 0.800449]\n",
      "EarlyStopping counter: 9 out of 30\n",
      "[Epoch: 92]   [loss avg: 8.628654]   [current loss: 0.840908]\n",
      "EarlyStopping counter: 10 out of 30\n",
      "[Epoch: 93]   [loss avg: 8.602875]   [current loss: 0.870223]\n",
      "EarlyStopping counter: 11 out of 30\n",
      "[Epoch: 94]   [loss avg: 8.579881]   [current loss: 1.011738]\n",
      "EarlyStopping counter: 12 out of 30\n",
      "[Epoch: 95]   [loss avg: 8.559672]   [current loss: 0.919894]\n",
      "EarlyStopping counter: 13 out of 30\n",
      "[Epoch: 96]   [loss avg: 8.539513]   [current loss: 0.877995]\n",
      "EarlyStopping counter: 14 out of 30\n",
      "[Epoch: 97]   [loss avg: 8.519037]   [current loss: 0.916870]\n",
      "EarlyStopping counter: 15 out of 30\n",
      "[Epoch: 98]   [loss avg: 8.495028]   [current loss: 0.800394]\n",
      "EarlyStopping counter: 16 out of 30\n",
      "[Epoch: 99]   [loss avg: 8.475180]   [current loss: 0.664947]\n",
      "EarlyStopping counter: 17 out of 30\n",
      "[Epoch: 100]   [loss avg: 8.452621]   [current loss: 0.630928]\n",
      "EarlyStopping counter: 18 out of 30\n",
      "[Epoch: 101]   [loss avg: 8.432080]   [current loss: 0.735278]\n",
      "EarlyStopping counter: 19 out of 30\n",
      "[Epoch: 102]   [loss avg: 8.414459]   [current loss: 0.845463]\n",
      "EarlyStopping counter: 20 out of 30\n",
      "[Epoch: 103]   [loss avg: 8.394945]   [current loss: 0.865189]\n",
      "EarlyStopping counter: 21 out of 30\n",
      "[Epoch: 104]   [loss avg: 8.371948]   [current loss: 0.756290]\n",
      "EarlyStopping counter: 22 out of 30\n",
      "[Epoch: 105]   [loss avg: 8.350656]   [current loss: 0.712608]\n",
      "EarlyStopping counter: 23 out of 30\n",
      "[Epoch: 106]   [loss avg: 8.333349]   [current loss: 0.708707]\n",
      "EarlyStopping counter: 24 out of 30\n",
      "[Epoch: 107]   [loss avg: 8.310977]   [current loss: 0.513554]\n",
      "Validation loss decreased (0.547663 --> 0.513554).  Saving model ...\n",
      "[Epoch: 108]   [loss avg: 8.288146]   [current loss: 0.624531]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 109]   [loss avg: 8.268542]   [current loss: 0.747894]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 110]   [loss avg: 8.250223]   [current loss: 0.848501]\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[Epoch: 111]   [loss avg: 8.233655]   [current loss: 0.728786]\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[Epoch: 112]   [loss avg: 8.217572]   [current loss: 0.673293]\n",
      "EarlyStopping counter: 5 out of 30\n",
      "[Epoch: 113]   [loss avg: 8.199686]   [current loss: 0.714828]\n",
      "EarlyStopping counter: 6 out of 30\n",
      "[Epoch: 114]   [loss avg: 8.181166]   [current loss: 0.754511]\n",
      "EarlyStopping counter: 7 out of 30\n",
      "[Epoch: 115]   [loss avg: 8.164091]   [current loss: 0.789332]\n",
      "EarlyStopping counter: 8 out of 30\n",
      "[Epoch: 116]   [loss avg: 8.147440]   [current loss: 0.713714]\n",
      "EarlyStopping counter: 9 out of 30\n",
      "[Epoch: 117]   [loss avg: 8.130511]   [current loss: 0.654576]\n",
      "EarlyStopping counter: 10 out of 30\n",
      "[Epoch: 118]   [loss avg: 8.113141]   [current loss: 0.822904]\n",
      "EarlyStopping counter: 11 out of 30\n",
      "[Epoch: 119]   [loss avg: 8.097285]   [current loss: 0.570026]\n",
      "EarlyStopping counter: 12 out of 30\n",
      "[Epoch: 120]   [loss avg: 8.080880]   [current loss: 0.673235]\n",
      "EarlyStopping counter: 13 out of 30\n",
      "[Epoch: 121]   [loss avg: 8.064855]   [current loss: 0.728072]\n",
      "EarlyStopping counter: 14 out of 30\n",
      "[Epoch: 122]   [loss avg: 8.050546]   [current loss: 0.924226]\n",
      "EarlyStopping counter: 15 out of 30\n",
      "[Epoch: 123]   [loss avg: 8.033458]   [current loss: 0.824206]\n",
      "EarlyStopping counter: 16 out of 30\n",
      "[Epoch: 124]   [loss avg: 8.023077]   [current loss: 0.708639]\n",
      "EarlyStopping counter: 17 out of 30\n",
      "[Epoch: 125]   [loss avg: 8.010045]   [current loss: 0.860147]\n",
      "EarlyStopping counter: 18 out of 30\n",
      "[Epoch: 126]   [loss avg: 7.995374]   [current loss: 0.846342]\n",
      "EarlyStopping counter: 19 out of 30\n",
      "[Epoch: 127]   [loss avg: 7.979482]   [current loss: 0.678171]\n",
      "EarlyStopping counter: 20 out of 30\n",
      "[Epoch: 128]   [loss avg: 7.961345]   [current loss: 0.605539]\n",
      "EarlyStopping counter: 21 out of 30\n",
      "[Epoch: 129]   [loss avg: 7.944993]   [current loss: 0.707905]\n",
      "EarlyStopping counter: 22 out of 30\n",
      "[Epoch: 130]   [loss avg: 7.932261]   [current loss: 0.669389]\n",
      "EarlyStopping counter: 23 out of 30\n",
      "[Epoch: 131]   [loss avg: 7.919700]   [current loss: 0.737093]\n",
      "EarlyStopping counter: 24 out of 30\n",
      "[Epoch: 132]   [loss avg: 7.906921]   [current loss: 0.740377]\n",
      "EarlyStopping counter: 25 out of 30\n",
      "[Epoch: 133]   [loss avg: 7.897831]   [current loss: 0.759611]\n",
      "EarlyStopping counter: 26 out of 30\n",
      "[Epoch: 134]   [loss avg: 7.885549]   [current loss: 0.781399]\n",
      "EarlyStopping counter: 27 out of 30\n",
      "[Epoch: 135]   [loss avg: 7.871362]   [current loss: 0.650930]\n",
      "EarlyStopping counter: 28 out of 30\n",
      "[Epoch: 136]   [loss avg: 7.863231]   [current loss: 0.933252]\n",
      "EarlyStopping counter: 29 out of 30\n",
      "[Epoch: 137]   [loss avg: 7.851727]   [current loss: 0.908384]\n",
      "EarlyStopping counter: 30 out of 30\n",
      "Early stopping\n",
      "Finished Training\n",
      "Training time:  12.127450227737427\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# net = WCNN(num_classes=16,wavelet='db1').to(device)\n",
    "net = WaveCnn(class_num,band_nums,patch_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "patience = 30\n",
    "early_stopping = EarlyStopping(patience,verbose=True)\n",
    "\n",
    "start = time.time()\n",
    "total_loss = 0\n",
    "net.train() #注意启用训练模式\n",
    "for epoch in range(200):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 优化器梯度归零\n",
    "        optimizer.zero_grad()\n",
    "        # 正向传播 +　反向传播 + 优化\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print('[Epoch: %d]   [loss avg: %.6f]   [current loss: %.6f]' %(epoch + 1, total_loss/(epoch+1), loss.item()))\n",
    "\n",
    "    early_stopping(loss,net)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "print('Finished Training')\n",
    "end = time.time()\n",
    "print('Training time: ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing time:  0.25099992752075195\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    0.6829    0.8116        41\n",
      "         1.0     0.9169    0.9447    0.9306      1285\n",
      "         2.0     0.9248    0.9384    0.9316       747\n",
      "         3.0     0.9830    0.8122    0.8895       213\n",
      "         4.0     0.9929    0.9678    0.9802       435\n",
      "         5.0     0.9865    0.9985    0.9924       657\n",
      "         6.0     0.8696    0.8000    0.8333        25\n",
      "         7.0     0.9663    1.0000    0.9829       430\n",
      "         8.0     1.0000    0.7222    0.8387        18\n",
      "         9.0     0.9536    0.9863    0.9697       875\n",
      "        10.0     0.9612    0.9869    0.9739      2210\n",
      "        11.0     0.9751    0.8071    0.8832       534\n",
      "        12.0     0.9735    0.9946    0.9840       185\n",
      "        13.0     0.9974    0.9956    0.9965      1139\n",
      "        14.0     0.9912    0.9741    0.9826       347\n",
      "        15.0     0.9302    0.9524    0.9412        84\n",
      "\n",
      "    accuracy                         0.9612      9225\n",
      "   macro avg     0.9639    0.9102    0.9326      9225\n",
      "weighted avg     0.9618    0.9612    0.9605      9225\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "count = 0\n",
    "# 模型测试\n",
    "net.eval()  #注意启用测试模式\n",
    "for inputs, _ in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = net(inputs)\n",
    "    outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
    "    if count == 0:\n",
    "        y_pred_test =  outputs\n",
    "        count = 1\n",
    "    else:\n",
    "        y_pred_test = np.concatenate( (y_pred_test, outputs) )\n",
    "\n",
    "\n",
    "        \n",
    "end = time.time()\n",
    "print('testing time: ', end-start)\n",
    "        \n",
    "# 生成分类报告\n",
    "classification = classification_report(ytest, y_pred_test, digits=4)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import truediv\n",
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc\n",
    "    \n",
    "def reports (X_test,y_test,name):\n",
    "    count = 0\n",
    "    # 模型测试\n",
    "    for inputs, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = net(inputs)\n",
    "        outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
    "        if count == 0:\n",
    "            y_pred =  outputs\n",
    "            count = 1\n",
    "        else:\n",
    "            y_pred = np.concatenate( (y_pred, outputs) )\n",
    "    \n",
    "    if name == 'IP':\n",
    "        target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n",
    "                          ,'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed', \n",
    "                         'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
    "                          'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n",
    "                          'Stone-Steel-Towers']\n",
    "    elif name == 'SA':\n",
    "        target_names = ['Brocoli_green_weeds_1','Brocoli_green_weeds_2','Fallow','Fallow_rough_plow','Fallow_smooth',\n",
    "                        'Stubble','Celery','Grapes_untrained','Soil_vinyard_develop','Corn_senesced_green_weeds',\n",
    "                        'Lettuce_romaine_4wk','Lettuce_romaine_5wk','Lettuce_romaine_6wk','Lettuce_romaine_7wk',\n",
    "                        'Vinyard_untrained','Vinyard_vertical_trellis']\n",
    "    elif name == 'PU':\n",
    "        target_names = ['Asphalt','Meadows','Gravel','Trees', 'Painted metal sheets','Bare Soil','Bitumen',\n",
    "                        'Self-Blocking Bricks','Shadows']\n",
    "    elif name == 'KSC':\n",
    "        target_names = ['Water','Mud_flats','Salt_marsh','Catiail_marsh','Spartina_marsh','Graminoid_marsh',\n",
    "                       'Hardwood_swamp','Oak-Broadleaf','Slash_Pine','CP-Oak','CP-hammock','Willow swamp',\n",
    "                       'Scrub']\n",
    "    elif name == 'Houston':\n",
    "        target_names = ['Healthy grass','Stressed grass','Synthetic grass','Trees','Soil','Water',\n",
    "                       'Residential','Commercial','Road','Highway','Railway','Parking Lot 1', 'Parking Lot 2', \n",
    "                       'Tennis Court', 'Running Track']\n",
    "    \n",
    "    classification = classification_report(y_test, y_pred, target_names=target_names)\n",
    "    oa = accuracy_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "    return classification, confusion, oa*100, each_acc*100, aa*100, kappa*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.11924119241192\n",
      "91.02341159439582\n",
      "95.56603323817644\n"
     ]
    }
   ],
   "source": [
    "classification, confusion, oa, each_acc, aa, kappa = reports(test_loader, ytest, dataset)\n",
    "\n",
    "print(oa)\n",
    "print(aa)\n",
    "print(kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "126e7dba9e31a2f4e2fdeaa18977348d147742daf45a57e7be21e8fe5c72a0e4"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('XJR')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
