{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e752bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import pywt\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from pytorchtools import EarlyStopping\n",
    "\n",
    "import scipy.io as sio \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report,cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eefbd708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(name):\n",
    "    data_path = os.path.join(os.getcwd(),'/media/dy113/disk1/Project_xjr/dataset')\n",
    "    if name == 'IP':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'IndianPines/Indian_pines_corrected.mat'))['indian_pines_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'IndianPines/Indian_pines_gt.mat'))['indian_pines_gt']\n",
    "    elif name == 'SA':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'Salinas/Salinas_corrected.mat'))['salinas_corrected']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'Salinas/Salinas_gt.mat'))['salinas_gt']\n",
    "    elif name == 'PU':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'PaviaU/PaviaU.mat'))['paviaU']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU/PaviaU_gt.mat'))['paviaU_gt']\n",
    "    elif name == 'KSC':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'KSC/KSC.mat'))['KSC']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'KSC/KSC_gt.mat'))['KSC_gt']\n",
    "    elif name == 'DISPU':\n",
    "        data = sio.loadmat(os.path.join(data_path, 'DISPU/PUtrain_gt.mat'))['PU_tgt']\n",
    "        labels = sio.loadmat(os.path.join(data_path, 'PaviaU/PaviaU_gt.mat'))['paviaU_gt']\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b41c69fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padWithZeros(X,margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2 * margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX\n",
    "\n",
    "def createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n",
    "    # 给 X 做 padding\n",
    "    margin = int((windowSize - 1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels\n",
    "\n",
    "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState, stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f77351c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 217, 204)\n",
      "(512, 217)\n",
      "Hyperspectral data shape:  (512, 217, 204)\n",
      "Label shape:  (512, 217)\n",
      "Band nums:  204\n"
     ]
    }
   ],
   "source": [
    "class_num = 16\n",
    "dataset = 'SA'\n",
    "batchsize = 64\n",
    "X, y = loadData(dataset)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "test_ratio = 0.99\n",
    "patch_size = 15\n",
    "band_nums = X.shape[2]\n",
    "pca_components = 15\n",
    "\n",
    "print('Hyperspectral data shape: ', X.shape)\n",
    "print('Label shape: ',y.shape)\n",
    "print('Band nums: ', X.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "546597dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyPCA(X, numComponents):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    pca = PCA(n_components=numComponents, whiten=True)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX,(X.shape[0],X.shape[1],numComponents))\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fded664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape after PCA:  (512, 217, 15)\n",
      "Data cube X shape:  (54129, 15, 15, 15)\n",
      "Data cube y shape:  (54129,)\n",
      "15\n",
      "Xtrain shape:  (541, 15, 15, 15)\n",
      "Xtest shape:  (53588, 15, 15, 15)\n",
      "ytrain shape:  (541,)\n",
      "ytest shape:  (53588,)\n",
      "before transpose: Xtrain shape:  (541, 15, 15, 15, 1)\n",
      "before transpose: Xtest  shape:  (53588, 15, 15, 15, 1)\n",
      "before transpose: Xtest  shape:  (53588, 15, 15, 15, 1)\n",
      "after transpose: Xtrain shape:  (541, 1, 15, 15, 15)\n",
      "after transpose: Xtest  shape:  (53588, 1, 15, 15, 15)\n"
     ]
    }
   ],
   "source": [
    "X_pca = applyPCA(X,numComponents=pca_components)\n",
    "print('Data shape after PCA: ',X_pca.shape)\n",
    "\n",
    "X_pca,y = createImageCubes(X_pca,y,windowSize=patch_size)\n",
    "print('Data cube X shape: ', X_pca.shape)\n",
    "print('Data cube y shape: ', y.shape)\n",
    "\n",
    "\n",
    "# X,y = createImageCubes(X,y,windowSize=patch_size)\n",
    "# print('Data cube X shape: ', X.shape)\n",
    "# print('Data cube y shape: ', y.shape)\n",
    "\n",
    "dim3=X_pca.shape[3]\n",
    "print(dim3)\n",
    "band_nums = dim3\n",
    "\n",
    "\n",
    "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X_pca, y, test_ratio)\n",
    "# Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, y, test_ratio)\n",
    "print('Xtrain shape: ',Xtrain.shape)\n",
    "print('Xtest shape: ',Xtest.shape)\n",
    "print('ytrain shape: ',ytrain.shape)\n",
    "print('ytest shape: ',ytest.shape)\n",
    "\n",
    "Xtrain = Xtrain.reshape(-1, patch_size, patch_size, Xtrain.shape[3], 1)\n",
    "Xtest  = Xtest.reshape(-1, patch_size, patch_size, Xtrain.shape[3], 1)\n",
    "print('before transpose: Xtrain shape: ', Xtrain.shape)\n",
    "print('before transpose: Xtest  shape: ', Xtest.shape)\n",
    "print('before transpose: Xtest  shape: ', Xtest.shape)\n",
    "\n",
    "# Xtrain = Xtrain.transpose(0, 4, 3, 2, 1)\n",
    "# Xtest  = Xtest.transpose(0, 4, 3, 2, 1)\n",
    "Xtrain = Xtrain.transpose(0, 4, 2, 1, 3)\n",
    "Xtest  = Xtest.transpose(0, 4, 2, 1, 3)\n",
    "print('after transpose: Xtrain shape: ', Xtrain.shape)\n",
    "print('after transpose: Xtest  shape: ', Xtest.shape)\n",
    "\n",
    "\n",
    "# Xtrain = Xtrain.transpose(0, 3, 1, 2)\n",
    "# Xtest  = Xtest.transpose(0, 3, 1, 2)\n",
    "# print('after transpose: Xtrain shape: ', Xtrain.shape)\n",
    "# print('after transpose: Xtest  shape: ', Xtest.shape)\n",
    "\n",
    "\n",
    "\n",
    "class TrainDS(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.len = Xtrain.shape[0]\n",
    "        self.x_data = torch.FloatTensor(Xtrain)\n",
    "        self.y_data = torch.LongTensor(ytrain)\n",
    "    def __getitem__(self, index):\n",
    "        # 根据索引返回数据和对应的标签\n",
    "        return self.x_data[index], self.y_data[index] \n",
    "    def __len__(self):\n",
    "        # 返回文件数据的数目\n",
    "        return self.len\n",
    "\n",
    "\n",
    "class TestDS(torch.utils.data.Dataset):\n",
    "    def __init__(self):\n",
    "        self.len = Xtest.shape[0]\n",
    "        self.x_data = torch.FloatTensor(Xtest)\n",
    "        self.y_data = torch.LongTensor(ytest)\n",
    "    def __getitem__(self, index):\n",
    "        # 根据索引返回数据和对应的标签\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    def __len__(self):\n",
    "        # 返回文件数据的数目\n",
    "        return self.len\n",
    "      \n",
    "\n",
    "trainset = TrainDS()\n",
    "testset  = TestDS()\n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=batchsize, shuffle=True, num_workers=0)\n",
    "test_loader  = torch.utils.data.DataLoader(dataset=testset,  batch_size=batchsize, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8914d1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wavelet(nn.Module):\n",
    "    \"\"\"This module extract wavelet coefficient defined in pywt\n",
    "    and create 3D convolution kernels to be able to use GPU\"\"\"\n",
    "\n",
    "    def _coef_h(self, in_planes, coef):\n",
    "        \"\"\"Construct the weight matrix for horizontal 3D convolution.\n",
    "        The weights are repeated on the diagonal\"\"\"\n",
    "        v = []\n",
    "        for i in range(in_planes):\n",
    "            l = []\n",
    "            for j in range(in_planes):\n",
    "                if i == j:\n",
    "                    l.append([[[c for c in coef]]])\n",
    "                else:\n",
    "                    l.append([[[0.0 for c in coef]]])\n",
    "            v.append(l)\n",
    "#         print(v)\n",
    "        return v\n",
    "\n",
    "    def _coef_v(self, in_planes, coef):\n",
    "        \"\"\"Construct the weight matrix for vertical 3D convolution.\n",
    "        The weights are repeated on the diagonal\"\"\"\n",
    "        v = []\n",
    "        for i in range(in_planes):\n",
    "            l = []\n",
    "            for j in range(in_planes):\n",
    "                if i == j:\n",
    "                    l.append([[[c] for c in coef]])\n",
    "                else:\n",
    "                    l.append([[[0.0] for c in coef]])\n",
    "            v.append(l)\n",
    "#         print(v)\n",
    "        return v\n",
    "\n",
    "    def _coef_d(self, in_planes, coef):\n",
    "        \"\"\"Construct the weight matrix for depth 3D convolution.\n",
    "        The weights are repeated on the diagonal\"\"\"\n",
    "        v = []\n",
    "        for i in range(in_planes):\n",
    "            l = []\n",
    "            for j in range(in_planes):\n",
    "                if i == j:\n",
    "                    l.append([[[c]] for c in coef])\n",
    "                else:\n",
    "                    l.append([[[0.0]] for c in coef])\n",
    "            v.append(l)\n",
    "#         print(v)\n",
    "        return v\n",
    "    \n",
    "    def __init__(self, in_planes, horizontal, vertical, name=\"db2\"):\n",
    "        super(Wavelet, self).__init__()\n",
    "\n",
    "        # Import wavelet coefficients\n",
    "        import pywt\n",
    "        wavelet = pywt.Wavelet(name)\n",
    "        coef_low = wavelet.dec_lo\n",
    "        coef_high = wavelet.dec_hi\n",
    "        # Determine the kernel 3D shape\n",
    "        nb_coeff = len(coef_low)\n",
    "        # print(nb_coeff)\n",
    "\n",
    "        if horizontal & (not vertical):\n",
    "            kernel_size = (1, 1, nb_coeff)\n",
    "            # stride = (1, 1, 2)\n",
    "            stride = (1, 1, 1)\n",
    "            pad = (nb_coeff // 2, nb_coeff - 1 - nb_coeff // 2, 0, 0, 0, 0)\n",
    "            weights_low = self._coef_h(in_planes, coef_low)\n",
    "            weights_high = self._coef_h(in_planes, coef_high)\n",
    "\n",
    "        elif (not horizontal) & vertical:\n",
    "            kernel_size = (1, nb_coeff, 1)\n",
    "            # stride = (1, 2, 1)\n",
    "            stride = (1, 1, 1)\n",
    "            pad = (0, 0, nb_coeff // 2, nb_coeff - 1 - nb_coeff // 2, 0, 0)\n",
    "            weights_low = self._coef_v(in_planes, coef_low)\n",
    "            weights_high = self._coef_v(in_planes, coef_high)\n",
    "\n",
    "        elif (not horizontal) & (not vertical):\n",
    "            kernel_size = (nb_coeff, 1, 1)\n",
    "            # stride = (2, 1, 1)\n",
    "            stride = (1, 1, 1)\n",
    "            pad = (0, 0, 0, 0, nb_coeff // 2, nb_coeff - 1 - nb_coeff // 2)\n",
    "            weights_low = self._coef_d(in_planes, coef_low)\n",
    "            weights_high = self._coef_d(in_planes, coef_high)\n",
    "           \n",
    "        # Create the conv2D\n",
    "        self.conv_high = nn.Conv3d(\n",
    "            in_planes, in_planes, kernel_size=kernel_size, stride=stride, bias=False)\n",
    "        self.conv_low = nn.Conv3d(\n",
    "            in_planes, in_planes, kernel_size=kernel_size, stride=stride, bias=False)\n",
    "        self.padding = nn.ReplicationPad3d(padding=pad)\n",
    "\n",
    "        # Replace their weights\n",
    "        self.conv_high.weight = torch.nn.Parameter(\n",
    "            data=torch.Tensor(weights_high), requires_grad=False)\n",
    "        self.conv_low.weight = torch.nn.Parameter(\n",
    "            data=torch.Tensor(weights_low), requires_grad=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Returns the approximation and detail part'''\n",
    "        x = self.padding(x)\n",
    "        return (self.conv_low(x), self.conv_high(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c2d216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wavelet3D(nn.Module):\n",
    "    def __init__(self, in_planes, name=\"db2\"):\n",
    "        super(Wavelet3D, self).__init__()\n",
    "        self.horizontal_wavelet = Wavelet(in_planes, horizontal=True, vertical=False, name=name)\n",
    "        self.vertical_wavelet = Wavelet(in_planes, horizontal=False, vertical=True,  name=name)\n",
    "        self.depth_wavelet = Wavelet(in_planes, horizontal=False, vertical=False,  name=name)\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''Returns (LL, LH, HL, HH)'''\n",
    "        (c, d) = self.horizontal_wavelet(x)\n",
    "        #print('H',c.size(),d.size())\n",
    "        (LL, LH) = self.vertical_wavelet(c)\n",
    "        #print('V',LL.size(),LH.size())\n",
    "        (HL, HH) = self.vertical_wavelet(d)\n",
    "        (LLL, LLH) = self.depth_wavelet(LL)\n",
    "        #print('D',LLL.size(),LLH.size())\n",
    "        (LHL, LHH) = self.depth_wavelet(LH)\n",
    "        (HLL, HLH) = self.depth_wavelet(HL)\n",
    "        (HHL, HHH) = self.depth_wavelet(HH)\n",
    "        return (LLL, LLH, LHL, LHH, HLL, HLH, HHL, HHH)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0066fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class waveblock(nn.Module):\n",
    "    def __init__(self, in_planes, name):\n",
    "        super(waveblock, self).__init__()\n",
    "        self.wavelet3d = Wavelet3D(in_planes,name=name)\n",
    "\n",
    "    def forward(self,x):\n",
    "        (LLL, LLH, LHL, LHH, HLL, HLH, HHL, HHH) = self.wavelet3d(x)\n",
    "        x = LLL\n",
    "        details = torch.cat([LLH, LHL, LHH, HLL, HLH, HHL, HHH],1)\n",
    "        return x,details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc0036ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConvBlock(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size,stride,padding=0):\n",
    "        super(BasicConvBlock, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm3d(out_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)    \n",
    "        self.conv1 = nn.Conv3d(in_planes,out_planes,kernel_size, stride=stride,\n",
    "                               padding=padding, bias=False)\n",
    "                   \n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn1(self.conv1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0530c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicConvBlock2D(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size,stride,padding=0):\n",
    "        super(BasicConvBlock2D, self).__init__()\n",
    "        self.bn1 = nn.BatchNorm2d(out_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_planes, out_planes,kernel_size, stride=stride,\n",
    "                               padding=padding, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn1(self.conv1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bc5505e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveCnntest(nn.Module):\n",
    "    def __init__(self, num_classes,band_nums,patch_size):\n",
    "        super(WaveCnntest, self).__init__() \n",
    "        # self.conv1 = BasicConvBlock2D(band_nums,patch_size,1,1,0)\n",
    "        \n",
    "        # self.conv0 = BasicConvBlock(1,1,(1,1,5),(1,1,2),1)\n",
    "        # self.conv01 = BasicConvBlock(1,1,(1,1,5),(1,1,2),1)\n",
    "        # self.conv02 = BasicConvBlock(1,1,(1,1,5),(1,1,2),1)\n",
    "\n",
    "        self.conv00 = BasicConvBlock(1,15,(1,1,7),(1,1,5),(0,0,1))\n",
    "        self.conv01 = BasicConvBlock(15,15,(1,1,20),(1,1,1),0)\n",
    "        # self.conv02 = BasicConvBlock(15,15,(1,1,5),(1,1,),1)\n",
    "        self.conv02 = BasicConvBlock(1,15,(1,1,band_nums),(1,1,1),0)\n",
    "\n",
    "        self.wave1 = waveblock(1, name=\"db1\")    \n",
    "#         self.wave2 = waveblock(1, name=\"db2\")\n",
    "#         self.wave3 = waveblock(1, name=\"db2\")\n",
    "\n",
    "        self.conv1 = BasicConvBlock(8,8,3,1,1)\n",
    "        self.conv2 = BasicConvBlock(1,8,3,1,1)\n",
    "\n",
    "        # self.conv3 = BasicConvBlock(32,32,3,1,1)\n",
    "                \n",
    "#         # bottleneck layer        \n",
    "        self.conv3 = nn.Sequential(\n",
    "                        BasicConvBlock(8,16,3,1),\n",
    "                        BasicConvBlock(16,8,3,1))\n",
    "        \n",
    "        self.pool = nn.MaxPool3d(kernel_size=3,stride=3)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x = self.conv00(x)\n",
    "        # # print(x.shape)\n",
    "        # # b=x.shape[4]\n",
    "        # # print(b)\n",
    "        # x = self.conv01(x)\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.conv02(x)\n",
    "        x = x.reshape(x.shape[0],1,x.shape[1],x.shape[1],x.shape[1]) \n",
    "        \n",
    "        # x = self.conv01(x)\n",
    "        # x = self.conv02(x)\n",
    "        # x = x.unsqueeze(1)\n",
    "        # # x = x.permute(0,1,3,4,2)\n",
    "\n",
    "        app1, det1 = self.wave1(x)\n",
    "        wave1 = torch.cat([app1, det1],1)\n",
    "        # x11 = self.conv1(wave1)\n",
    "\n",
    "         # x1 = self.conv2(x)          \n",
    "        # x2 = torch.cat([x1, x11],1)\n",
    "        # x2 = torch.cat([x1, wave1],1)\n",
    "\n",
    "        x2 = wave1\n",
    "\n",
    "        x3 = self.conv3(x2)  \n",
    "        # x3 = self.conv3(x2)        \n",
    "        # x3 = self.conv4(x2)\n",
    "        x3 = self.pool(x3)       \n",
    "\n",
    "        x3 = x3.reshape(x3.shape[0],-1)\n",
    "                       \n",
    "\n",
    "#         app2, det2 = self.wave2(app1)\n",
    "#         wave2 = torch.cat([app2, det2],1)\n",
    "             \n",
    "#         x2 = self.conv3(wave2)        \n",
    "#         x2 = torch.cat([wave2,x2,x1],1)  \n",
    "        \n",
    "#         x2 = self.conv4(x2)\n",
    "#         x2 = x2.reshape(x2.shape[0],-1)\n",
    "      \n",
    "#         app2, det2 = self.wave2(app1)\n",
    "#         wave2 = torch.cat([app2, det2],1)\n",
    "#         x2 = self.conv2(wave2)\n",
    "        \n",
    "#         app3, det3 = self.wave3(app2)\n",
    "#         wave3 = torch.cat([app3, det3],1)\n",
    "#         x3 = self.conv2(wave3)\n",
    "               \n",
    "#         app4, det4 = self.wave3(app3)\n",
    "#         wave4 = torch.cat([app4, det4],1)\n",
    "#         x4 = self.conv2(wave4)\n",
    "                            \n",
    "#         x4 = torch.cat([wave1,x1,wave2,x2,wave3,x3,wave4,x4],1)    \n",
    "# #         print(x3.shape)\n",
    "#         x4 = self.conv3(x4)\n",
    "# #         x3 = self.pool(x3)\n",
    "#         x4 = x4.reshape(x4.shape[0],-1)\n",
    "# #         flat = x3.shape[1]  \n",
    "# #         print(flat)\n",
    "        \n",
    "        return x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8cd25002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res torch.Size([1024, 216])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "#     input = torch.randn(1024,band_nums,patch_size, patch_size)\n",
    "#     input = torch.randn(1, 3, 15, 15, 15)\n",
    "    # input = torch.randn(1024,1,patch_size, patch_size,pca_components)\n",
    "    input = torch.randn(1024,1,patch_size, patch_size,dim3)\n",
    "    m_net = WaveCnntest(class_num,band_nums,patch_size)\n",
    "    res = m_net(input)\n",
    "    print('res',res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "487448ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveCnn(nn.Module):\n",
    "    def __init__(self, num_classes,band_nums,patch_size):\n",
    "        super(WaveCnn, self).__init__()  \n",
    "        # self.conv1 = BasicConvBlock2D(band_nums,patch_size,1,1,0)\n",
    "        \n",
    "        self.conv00 = BasicConvBlock(1,15,(1,1,7),(1,1,5),(0,0,1))\n",
    "        self.conv01 = BasicConvBlock(15,15,(1,1,20),(1,1,1),0)\n",
    "        self.conv02 = BasicConvBlock(1,patch_size,(1,1,band_nums),(1,1,1),0)\n",
    "\n",
    "        self.wave1 = waveblock(1, name=\"db1\")    \n",
    "        self.wave2 = waveblock(1, name=\"db2\")\n",
    "\n",
    "        self.conv1 = BasicConvBlock(8,8,3,1,1)\n",
    "        self.conv2 = BasicConvBlock(1,8,3,1,1)\n",
    "                \n",
    "#         # bottleneck layer        \n",
    "        self.conv3 = nn.Sequential(\n",
    "                        BasicConvBlock(8,16,3,1),\n",
    "                        BasicConvBlock(16,8,3,1))\n",
    "        \n",
    "        self.pool = nn.MaxPool3d(kernel_size=3,stride=3)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "                            # nn.Linear(1536,256),\n",
    "                            nn.Linear(216,128),\n",
    "                            # nn.Linear(1280,256),\n",
    "                            nn.Dropout(p=0.4),\n",
    "                            nn.ReLU(inplace = True),\n",
    "                            # nn.Linear(256,128),\n",
    "                            # nn.Dropout(p=0.4),\n",
    "                            # nn.ReLU(inplace = True),\n",
    "                            nn.Linear(128,num_classes),\n",
    "                            nn.Dropout(p=0.4))                     \n",
    "        \n",
    "    def forward(self,x):\n",
    "        # x = self.conv00(x)\n",
    "        # x = self.conv01(x)\n",
    "        # # print(x.shape)\n",
    "\n",
    "        x = self.conv02(x)\n",
    "        x = x.reshape(x.shape[0],1,x.shape[1],x.shape[1],x.shape[1]) \n",
    "           \n",
    "        # x = self.conv01(x)\n",
    "        # x = self.conv02(x)\n",
    "        # x = x.unsqueeze(1)\n",
    "        # # x = x.permute(0,1,3,4,2)\n",
    "\n",
    "        app1, det1 = self.wave1(x)\n",
    "        wave1 = torch.cat([app1, det1],1)\n",
    "        # x11 = self.conv1(wave1)\n",
    "\n",
    "        # x1 = self.conv2(x)          \n",
    "        # x2 = torch.cat([x1, x11],1)\n",
    "        # x2 = torch.cat([x1, wave1],1)\n",
    "\n",
    "        x2 = wave1\n",
    "        \n",
    "        x3 = self.conv3(x2)        \n",
    "        x3 = self.pool(x3)       \n",
    "        x3 = x3.reshape(x3.shape[0],-1)\n",
    "                       \n",
    "        out = self.classifier(x3)     \n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c09b9730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res torch.Size([1024, 16])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # input = torch.randn(1024,1,patch_size, patch_size,pca_components)\n",
    "    input = torch.randn(1024,1,patch_size, patch_size,dim3)\n",
    "    m_net = WaveCnn(class_num,band_nums,patch_size)\n",
    "    res = m_net(input)\n",
    "    print('res',res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6073f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv3d-1        [-1, 15, 15, 15, 1]             225\n",
      "       BatchNorm3d-2        [-1, 15, 15, 15, 1]              30\n",
      "              ReLU-3        [-1, 15, 15, 15, 1]               0\n",
      "    BasicConvBlock-4        [-1, 15, 15, 15, 1]               0\n",
      "  ReplicationPad3d-5        [-1, 1, 15, 15, 16]               0\n",
      "            Conv3d-6        [-1, 1, 15, 15, 15]               2\n",
      "            Conv3d-7        [-1, 1, 15, 15, 15]               2\n",
      "           Wavelet-8  [[-1, 1, 15, 15, 15], [-1, 1, 15, 15, 15]]               0\n",
      "  ReplicationPad3d-9        [-1, 1, 15, 16, 15]               0\n",
      "           Conv3d-10        [-1, 1, 15, 15, 15]               2\n",
      "           Conv3d-11        [-1, 1, 15, 15, 15]               2\n",
      "          Wavelet-12  [[-1, 1, 15, 15, 15], [-1, 1, 15, 15, 15]]               0\n",
      " ReplicationPad3d-13        [-1, 1, 15, 16, 15]               0\n",
      "           Conv3d-14        [-1, 1, 15, 15, 15]               2\n",
      "           Conv3d-15        [-1, 1, 15, 15, 15]               2\n",
      "          Wavelet-16  [[-1, 1, 15, 15, 15], [-1, 1, 15, 15, 15]]               0\n",
      " ReplicationPad3d-17        [-1, 1, 16, 15, 15]               0\n",
      "           Conv3d-18        [-1, 1, 15, 15, 15]               2\n",
      "           Conv3d-19        [-1, 1, 15, 15, 15]               2\n",
      "          Wavelet-20  [[-1, 1, 15, 15, 15], [-1, 1, 15, 15, 15]]               0\n",
      " ReplicationPad3d-21        [-1, 1, 16, 15, 15]               0\n",
      "           Conv3d-22        [-1, 1, 15, 15, 15]               2\n",
      "           Conv3d-23        [-1, 1, 15, 15, 15]               2\n",
      "          Wavelet-24  [[-1, 1, 15, 15, 15], [-1, 1, 15, 15, 15]]               0\n",
      " ReplicationPad3d-25        [-1, 1, 16, 15, 15]               0\n",
      "           Conv3d-26        [-1, 1, 15, 15, 15]               2\n",
      "           Conv3d-27        [-1, 1, 15, 15, 15]               2\n",
      "          Wavelet-28  [[-1, 1, 15, 15, 15], [-1, 1, 15, 15, 15]]               0\n",
      " ReplicationPad3d-29        [-1, 1, 16, 15, 15]               0\n",
      "           Conv3d-30        [-1, 1, 15, 15, 15]               2\n",
      "           Conv3d-31        [-1, 1, 15, 15, 15]               2\n",
      "          Wavelet-32  [[-1, 1, 15, 15, 15], [-1, 1, 15, 15, 15]]               0\n",
      "        Wavelet3D-33  [[-1, 1, 15, 15, 15], [-1, 1, 15, 15, 15], [-1, 1, 15, 15, 15], [-1, 1, 15, 15, 15], [-1, 1, 15, 15, 15], [-1, 1, 15, 15, 15], [-1, 1, 15, 15, 15], [-1, 1, 15, 15, 15]]               0\n",
      "        waveblock-34  [[-1, 1, 15, 15, 15], [-1, 7, 15, 15, 15]]               0\n",
      "           Conv3d-35       [-1, 16, 13, 13, 13]           3,456\n",
      "      BatchNorm3d-36       [-1, 16, 13, 13, 13]              32\n",
      "             ReLU-37       [-1, 16, 13, 13, 13]               0\n",
      "   BasicConvBlock-38       [-1, 16, 13, 13, 13]               0\n",
      "           Conv3d-39        [-1, 8, 11, 11, 11]           3,456\n",
      "      BatchNorm3d-40        [-1, 8, 11, 11, 11]              16\n",
      "             ReLU-41        [-1, 8, 11, 11, 11]               0\n",
      "   BasicConvBlock-42        [-1, 8, 11, 11, 11]               0\n",
      "        MaxPool3d-43           [-1, 8, 3, 3, 3]               0\n",
      "           Linear-44                  [-1, 128]          27,776\n",
      "          Dropout-45                  [-1, 128]               0\n",
      "             ReLU-46                  [-1, 128]               0\n",
      "           Linear-47                   [-1, 16]           2,064\n",
      "          Dropout-48                   [-1, 16]               0\n",
      "================================================================\n",
      "Total params: 37,083\n",
      "Trainable params: 37,055\n",
      "Non-trainable params: 28\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 36602051458303.12\n",
      "Params size (MB): 0.14\n",
      "Estimated Total Size (MB): 36602051458303.28\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "modelsum = WaveCnn(class_num,band_nums,patch_size).to(device)\n",
    "# print(modelsum)\n",
    "# summary(modelsum,(1,patch_size,patch_size,pca_components))\n",
    "summary(modelsum,(1,patch_size,patch_size,dim3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7da41c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch: 1]   [loss avg: 24.416433]   [current loss: 2.805534]\n",
      "Validation loss decreased (inf --> 2.805534).  Saving model ...\n",
      "[Epoch: 2]   [loss avg: 22.804754]   [current loss: 2.357686]\n",
      "Validation loss decreased (2.805534 --> 2.357686).  Saving model ...\n",
      "[Epoch: 3]   [loss avg: 21.880582]   [current loss: 2.479681]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 4]   [loss avg: 20.997437]   [current loss: 1.957170]\n",
      "Validation loss decreased (2.357686 --> 1.957170).  Saving model ...\n",
      "[Epoch: 5]   [loss avg: 20.013344]   [current loss: 1.594027]\n",
      "Validation loss decreased (1.957170 --> 1.594027).  Saving model ...\n",
      "[Epoch: 6]   [loss avg: 19.124608]   [current loss: 1.651574]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 7]   [loss avg: 18.326313]   [current loss: 1.518794]\n",
      "Validation loss decreased (1.594027 --> 1.518794).  Saving model ...\n",
      "[Epoch: 8]   [loss avg: 17.724023]   [current loss: 1.663420]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 9]   [loss avg: 17.154218]   [current loss: 1.573581]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 10]   [loss avg: 16.630198]   [current loss: 1.388009]\n",
      "Validation loss decreased (1.518794 --> 1.388009).  Saving model ...\n",
      "[Epoch: 11]   [loss avg: 16.171825]   [current loss: 1.116581]\n",
      "Validation loss decreased (1.388009 --> 1.116581).  Saving model ...\n",
      "[Epoch: 12]   [loss avg: 15.724891]   [current loss: 1.237210]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 13]   [loss avg: 15.299668]   [current loss: 1.032981]\n",
      "Validation loss decreased (1.116581 --> 1.032981).  Saving model ...\n",
      "[Epoch: 14]   [loss avg: 14.981695]   [current loss: 1.030332]\n",
      "Validation loss decreased (1.032981 --> 1.030332).  Saving model ...\n",
      "[Epoch: 15]   [loss avg: 14.699850]   [current loss: 1.317128]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 16]   [loss avg: 14.424841]   [current loss: 1.286297]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 17]   [loss avg: 14.210545]   [current loss: 1.524937]\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[Epoch: 18]   [loss avg: 13.962814]   [current loss: 0.805056]\n",
      "Validation loss decreased (1.030332 --> 0.805056).  Saving model ...\n",
      "[Epoch: 19]   [loss avg: 13.765339]   [current loss: 1.422281]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 20]   [loss avg: 13.551245]   [current loss: 1.176761]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 21]   [loss avg: 13.363597]   [current loss: 1.296060]\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[Epoch: 22]   [loss avg: 13.183006]   [current loss: 1.161029]\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[Epoch: 23]   [loss avg: 13.000877]   [current loss: 1.193539]\n",
      "EarlyStopping counter: 5 out of 30\n",
      "[Epoch: 24]   [loss avg: 12.859342]   [current loss: 1.379309]\n",
      "EarlyStopping counter: 6 out of 30\n",
      "[Epoch: 25]   [loss avg: 12.692953]   [current loss: 0.913647]\n",
      "EarlyStopping counter: 7 out of 30\n",
      "[Epoch: 26]   [loss avg: 12.543731]   [current loss: 1.077407]\n",
      "EarlyStopping counter: 8 out of 30\n",
      "[Epoch: 27]   [loss avg: 12.398827]   [current loss: 0.991034]\n",
      "EarlyStopping counter: 9 out of 30\n",
      "[Epoch: 28]   [loss avg: 12.265435]   [current loss: 0.904904]\n",
      "EarlyStopping counter: 10 out of 30\n",
      "[Epoch: 29]   [loss avg: 12.140918]   [current loss: 1.006055]\n",
      "EarlyStopping counter: 11 out of 30\n",
      "[Epoch: 30]   [loss avg: 12.015719]   [current loss: 0.662047]\n",
      "Validation loss decreased (0.805056 --> 0.662047).  Saving model ...\n",
      "[Epoch: 31]   [loss avg: 11.903230]   [current loss: 1.218749]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 32]   [loss avg: 11.781839]   [current loss: 0.600814]\n",
      "Validation loss decreased (0.662047 --> 0.600814).  Saving model ...\n",
      "[Epoch: 33]   [loss avg: 11.662014]   [current loss: 0.893811]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 34]   [loss avg: 11.555455]   [current loss: 1.069147]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 35]   [loss avg: 11.462239]   [current loss: 0.945327]\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[Epoch: 36]   [loss avg: 11.352012]   [current loss: 0.703780]\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[Epoch: 37]   [loss avg: 11.250110]   [current loss: 0.918822]\n",
      "EarlyStopping counter: 5 out of 30\n",
      "[Epoch: 38]   [loss avg: 11.170724]   [current loss: 1.033640]\n",
      "EarlyStopping counter: 6 out of 30\n",
      "[Epoch: 39]   [loss avg: 11.105047]   [current loss: 1.065354]\n",
      "EarlyStopping counter: 7 out of 30\n",
      "[Epoch: 40]   [loss avg: 11.039907]   [current loss: 1.035385]\n",
      "EarlyStopping counter: 8 out of 30\n",
      "[Epoch: 41]   [loss avg: 10.967134]   [current loss: 1.016181]\n",
      "EarlyStopping counter: 9 out of 30\n",
      "[Epoch: 42]   [loss avg: 10.897668]   [current loss: 1.060498]\n",
      "EarlyStopping counter: 10 out of 30\n",
      "[Epoch: 43]   [loss avg: 10.820597]   [current loss: 0.971658]\n",
      "EarlyStopping counter: 11 out of 30\n",
      "[Epoch: 44]   [loss avg: 10.755115]   [current loss: 0.873842]\n",
      "EarlyStopping counter: 12 out of 30\n",
      "[Epoch: 45]   [loss avg: 10.685305]   [current loss: 0.698870]\n",
      "EarlyStopping counter: 13 out of 30\n",
      "[Epoch: 46]   [loss avg: 10.619597]   [current loss: 0.976968]\n",
      "EarlyStopping counter: 14 out of 30\n",
      "[Epoch: 47]   [loss avg: 10.568959]   [current loss: 1.011570]\n",
      "EarlyStopping counter: 15 out of 30\n",
      "[Epoch: 48]   [loss avg: 10.516081]   [current loss: 0.670948]\n",
      "EarlyStopping counter: 16 out of 30\n",
      "[Epoch: 49]   [loss avg: 10.462056]   [current loss: 0.756388]\n",
      "EarlyStopping counter: 17 out of 30\n",
      "[Epoch: 50]   [loss avg: 10.394783]   [current loss: 0.651280]\n",
      "EarlyStopping counter: 18 out of 30\n",
      "[Epoch: 51]   [loss avg: 10.339834]   [current loss: 0.924586]\n",
      "EarlyStopping counter: 19 out of 30\n",
      "[Epoch: 52]   [loss avg: 10.282977]   [current loss: 0.796098]\n",
      "EarlyStopping counter: 20 out of 30\n",
      "[Epoch: 53]   [loss avg: 10.239024]   [current loss: 1.073522]\n",
      "EarlyStopping counter: 21 out of 30\n",
      "[Epoch: 54]   [loss avg: 10.207098]   [current loss: 0.849196]\n",
      "EarlyStopping counter: 22 out of 30\n",
      "[Epoch: 55]   [loss avg: 10.152802]   [current loss: 0.854043]\n",
      "EarlyStopping counter: 23 out of 30\n",
      "[Epoch: 56]   [loss avg: 10.109285]   [current loss: 0.814725]\n",
      "EarlyStopping counter: 24 out of 30\n",
      "[Epoch: 57]   [loss avg: 10.063499]   [current loss: 0.959696]\n",
      "EarlyStopping counter: 25 out of 30\n",
      "[Epoch: 58]   [loss avg: 10.004806]   [current loss: 0.955891]\n",
      "EarlyStopping counter: 26 out of 30\n",
      "[Epoch: 59]   [loss avg: 9.948179]   [current loss: 0.567391]\n",
      "Validation loss decreased (0.600814 --> 0.567391).  Saving model ...\n",
      "[Epoch: 60]   [loss avg: 9.903357]   [current loss: 0.776442]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 61]   [loss avg: 9.863968]   [current loss: 0.836417]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 62]   [loss avg: 9.819075]   [current loss: 1.195223]\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[Epoch: 63]   [loss avg: 9.773083]   [current loss: 0.798453]\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[Epoch: 64]   [loss avg: 9.741046]   [current loss: 0.625802]\n",
      "EarlyStopping counter: 5 out of 30\n",
      "[Epoch: 65]   [loss avg: 9.697925]   [current loss: 0.765442]\n",
      "EarlyStopping counter: 6 out of 30\n",
      "[Epoch: 66]   [loss avg: 9.665556]   [current loss: 0.631611]\n",
      "EarlyStopping counter: 7 out of 30\n",
      "[Epoch: 67]   [loss avg: 9.633746]   [current loss: 0.767678]\n",
      "EarlyStopping counter: 8 out of 30\n",
      "[Epoch: 68]   [loss avg: 9.603701]   [current loss: 1.089009]\n",
      "EarlyStopping counter: 9 out of 30\n",
      "[Epoch: 69]   [loss avg: 9.581185]   [current loss: 1.032084]\n",
      "EarlyStopping counter: 10 out of 30\n",
      "[Epoch: 70]   [loss avg: 9.537730]   [current loss: 0.655730]\n",
      "EarlyStopping counter: 11 out of 30\n",
      "[Epoch: 71]   [loss avg: 9.512768]   [current loss: 0.983848]\n",
      "EarlyStopping counter: 12 out of 30\n",
      "[Epoch: 72]   [loss avg: 9.486125]   [current loss: 1.025708]\n",
      "EarlyStopping counter: 13 out of 30\n",
      "[Epoch: 73]   [loss avg: 9.455155]   [current loss: 1.257728]\n",
      "EarlyStopping counter: 14 out of 30\n",
      "[Epoch: 74]   [loss avg: 9.426273]   [current loss: 0.786672]\n",
      "EarlyStopping counter: 15 out of 30\n",
      "[Epoch: 75]   [loss avg: 9.392685]   [current loss: 0.366010]\n",
      "Validation loss decreased (0.567391 --> 0.366010).  Saving model ...\n",
      "[Epoch: 76]   [loss avg: 9.366469]   [current loss: 0.843374]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 77]   [loss avg: 9.334463]   [current loss: 0.552358]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 78]   [loss avg: 9.306879]   [current loss: 0.840792]\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[Epoch: 79]   [loss avg: 9.284619]   [current loss: 1.126412]\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[Epoch: 80]   [loss avg: 9.254994]   [current loss: 0.749156]\n",
      "EarlyStopping counter: 5 out of 30\n",
      "[Epoch: 81]   [loss avg: 9.239058]   [current loss: 0.996065]\n",
      "EarlyStopping counter: 6 out of 30\n",
      "[Epoch: 82]   [loss avg: 9.208959]   [current loss: 0.831290]\n",
      "EarlyStopping counter: 7 out of 30\n",
      "[Epoch: 83]   [loss avg: 9.183263]   [current loss: 0.831021]\n",
      "EarlyStopping counter: 8 out of 30\n",
      "[Epoch: 84]   [loss avg: 9.162241]   [current loss: 0.865001]\n",
      "EarlyStopping counter: 9 out of 30\n",
      "[Epoch: 85]   [loss avg: 9.131556]   [current loss: 0.851978]\n",
      "EarlyStopping counter: 10 out of 30\n",
      "[Epoch: 86]   [loss avg: 9.110098]   [current loss: 1.041584]\n",
      "EarlyStopping counter: 11 out of 30\n",
      "[Epoch: 87]   [loss avg: 9.096369]   [current loss: 0.720219]\n",
      "EarlyStopping counter: 12 out of 30\n",
      "[Epoch: 88]   [loss avg: 9.082135]   [current loss: 0.794956]\n",
      "EarlyStopping counter: 13 out of 30\n",
      "[Epoch: 89]   [loss avg: 9.055400]   [current loss: 0.627937]\n",
      "EarlyStopping counter: 14 out of 30\n",
      "[Epoch: 90]   [loss avg: 9.031265]   [current loss: 0.584688]\n",
      "EarlyStopping counter: 15 out of 30\n",
      "[Epoch: 91]   [loss avg: 9.001170]   [current loss: 0.595962]\n",
      "EarlyStopping counter: 16 out of 30\n",
      "[Epoch: 92]   [loss avg: 8.981367]   [current loss: 1.011052]\n",
      "EarlyStopping counter: 17 out of 30\n",
      "[Epoch: 93]   [loss avg: 8.960359]   [current loss: 0.606996]\n",
      "EarlyStopping counter: 18 out of 30\n",
      "[Epoch: 94]   [loss avg: 8.940360]   [current loss: 0.936222]\n",
      "EarlyStopping counter: 19 out of 30\n",
      "[Epoch: 95]   [loss avg: 8.921376]   [current loss: 0.585677]\n",
      "EarlyStopping counter: 20 out of 30\n",
      "[Epoch: 96]   [loss avg: 8.896949]   [current loss: 0.530748]\n",
      "EarlyStopping counter: 21 out of 30\n",
      "[Epoch: 97]   [loss avg: 8.886372]   [current loss: 0.952964]\n",
      "EarlyStopping counter: 22 out of 30\n",
      "[Epoch: 98]   [loss avg: 8.862053]   [current loss: 0.695620]\n",
      "EarlyStopping counter: 23 out of 30\n",
      "[Epoch: 99]   [loss avg: 8.846123]   [current loss: 1.071354]\n",
      "EarlyStopping counter: 24 out of 30\n",
      "[Epoch: 100]   [loss avg: 8.834256]   [current loss: 0.665023]\n",
      "EarlyStopping counter: 25 out of 30\n",
      "[Epoch: 101]   [loss avg: 8.813455]   [current loss: 0.360932]\n",
      "Validation loss decreased (0.366010 --> 0.360932).  Saving model ...\n",
      "[Epoch: 102]   [loss avg: 8.797859]   [current loss: 1.015805]\n",
      "EarlyStopping counter: 1 out of 30\n",
      "[Epoch: 103]   [loss avg: 8.779644]   [current loss: 0.924137]\n",
      "EarlyStopping counter: 2 out of 30\n",
      "[Epoch: 104]   [loss avg: 8.758392]   [current loss: 0.450204]\n",
      "EarlyStopping counter: 3 out of 30\n",
      "[Epoch: 105]   [loss avg: 8.743633]   [current loss: 0.771777]\n",
      "EarlyStopping counter: 4 out of 30\n",
      "[Epoch: 106]   [loss avg: 8.728873]   [current loss: 0.716447]\n",
      "EarlyStopping counter: 5 out of 30\n",
      "[Epoch: 107]   [loss avg: 8.711948]   [current loss: 0.635339]\n",
      "EarlyStopping counter: 6 out of 30\n",
      "[Epoch: 108]   [loss avg: 8.697562]   [current loss: 0.880881]\n",
      "EarlyStopping counter: 7 out of 30\n",
      "[Epoch: 109]   [loss avg: 8.682569]   [current loss: 0.612558]\n",
      "EarlyStopping counter: 8 out of 30\n",
      "[Epoch: 110]   [loss avg: 8.664694]   [current loss: 1.327041]\n",
      "EarlyStopping counter: 9 out of 30\n",
      "[Epoch: 111]   [loss avg: 8.652694]   [current loss: 1.091132]\n",
      "EarlyStopping counter: 10 out of 30\n",
      "[Epoch: 112]   [loss avg: 8.640944]   [current loss: 0.464153]\n",
      "EarlyStopping counter: 11 out of 30\n",
      "[Epoch: 113]   [loss avg: 8.637846]   [current loss: 0.939611]\n",
      "EarlyStopping counter: 12 out of 30\n",
      "[Epoch: 114]   [loss avg: 8.624652]   [current loss: 0.746127]\n",
      "EarlyStopping counter: 13 out of 30\n",
      "[Epoch: 115]   [loss avg: 8.613657]   [current loss: 0.929012]\n",
      "EarlyStopping counter: 14 out of 30\n",
      "[Epoch: 116]   [loss avg: 8.608634]   [current loss: 1.279500]\n",
      "EarlyStopping counter: 15 out of 30\n",
      "[Epoch: 117]   [loss avg: 8.595455]   [current loss: 0.611446]\n",
      "EarlyStopping counter: 16 out of 30\n",
      "[Epoch: 118]   [loss avg: 8.584585]   [current loss: 0.870299]\n",
      "EarlyStopping counter: 17 out of 30\n",
      "[Epoch: 119]   [loss avg: 8.576687]   [current loss: 0.805323]\n",
      "EarlyStopping counter: 18 out of 30\n",
      "[Epoch: 120]   [loss avg: 8.567457]   [current loss: 0.694429]\n",
      "EarlyStopping counter: 19 out of 30\n",
      "[Epoch: 121]   [loss avg: 8.557543]   [current loss: 0.944929]\n",
      "EarlyStopping counter: 20 out of 30\n",
      "[Epoch: 122]   [loss avg: 8.549459]   [current loss: 0.801674]\n",
      "EarlyStopping counter: 21 out of 30\n",
      "[Epoch: 123]   [loss avg: 8.536062]   [current loss: 0.647978]\n",
      "EarlyStopping counter: 22 out of 30\n",
      "[Epoch: 124]   [loss avg: 8.527348]   [current loss: 0.845930]\n",
      "EarlyStopping counter: 23 out of 30\n",
      "[Epoch: 125]   [loss avg: 8.517342]   [current loss: 1.151924]\n",
      "EarlyStopping counter: 24 out of 30\n",
      "[Epoch: 126]   [loss avg: 8.507196]   [current loss: 0.986346]\n",
      "EarlyStopping counter: 25 out of 30\n",
      "[Epoch: 127]   [loss avg: 8.496550]   [current loss: 0.673158]\n",
      "EarlyStopping counter: 26 out of 30\n",
      "[Epoch: 128]   [loss avg: 8.486403]   [current loss: 0.450517]\n",
      "EarlyStopping counter: 27 out of 30\n",
      "[Epoch: 129]   [loss avg: 8.478726]   [current loss: 1.148369]\n",
      "EarlyStopping counter: 28 out of 30\n",
      "[Epoch: 130]   [loss avg: 8.468087]   [current loss: 0.978717]\n",
      "EarlyStopping counter: 29 out of 30\n",
      "[Epoch: 131]   [loss avg: 8.456870]   [current loss: 0.637023]\n",
      "EarlyStopping counter: 30 out of 30\n",
      "Early stopping\n",
      "Finished Training\n",
      "Training time:  12.3070068359375\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# net = WCNN(num_classes=16,wavelet='db1').to(device)\n",
    "net = WaveCnn(class_num,band_nums,patch_size).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "patience = 30\n",
    "early_stopping = EarlyStopping(patience,verbose=True)\n",
    "\n",
    "start = time.time()\n",
    "total_loss = 0\n",
    "net.train() #注意启用训练模式\n",
    "for epoch in range(200):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # 优化器梯度归零\n",
    "        optimizer.zero_grad()\n",
    "        # 正向传播 +　反向传播 + 优化\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print('[Epoch: %d]   [loss avg: %.6f]   [current loss: %.6f]' %(epoch + 1, total_loss/(epoch+1), loss.item()))\n",
    "\n",
    "    early_stopping(loss,net)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "print('Finished Training')\n",
    "end = time.time()\n",
    "print('Training time: ', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6173bb82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing time:  1.7966318130493164\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9965    0.9980    0.9972      1989\n",
      "         1.0     0.9997    1.0000    0.9999      3689\n",
      "         2.0     0.9765    0.9995    0.9879      1956\n",
      "         3.0     0.9630    0.9986    0.9804      1380\n",
      "         4.0     0.9992    0.9619    0.9802      2651\n",
      "         5.0     0.9969    1.0000    0.9985      3920\n",
      "         6.0     1.0000    0.9977    0.9989      3543\n",
      "         7.0     0.8964    0.9792    0.9360     11158\n",
      "         8.0     0.9998    0.9993    0.9996      6141\n",
      "         9.0     0.9991    0.9864    0.9927      3245\n",
      "        10.0     0.9940    0.9376    0.9649      1057\n",
      "        11.0     0.9646    1.0000    0.9820      1908\n",
      "        12.0     1.0000    0.7652    0.8670       907\n",
      "        13.0     0.8224    0.9972    0.9014      1059\n",
      "        14.0     0.9611    0.8275    0.8893      7196\n",
      "        15.0     0.9972    0.9888    0.9930      1789\n",
      "\n",
      "    accuracy                         0.9638     53588\n",
      "   macro avg     0.9729    0.9648    0.9668     53588\n",
      "weighted avg     0.9659    0.9638    0.9633     53588\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "count = 0\n",
    "# 模型测试\n",
    "net.eval()  #注意启用测试模式\n",
    "for inputs, _ in test_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    outputs = net(inputs)\n",
    "    outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
    "    if count == 0:\n",
    "        y_pred_test =  outputs\n",
    "        count = 1\n",
    "    else:\n",
    "        y_pred_test = np.concatenate( (y_pred_test, outputs) )\n",
    "\n",
    "\n",
    "        \n",
    "end = time.time()\n",
    "print('testing time: ', end-start)\n",
    "        \n",
    "# 生成分类报告\n",
    "classification = classification_report(ytest, y_pred_test, digits=4)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aa0a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import truediv\n",
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc\n",
    "    \n",
    "def reports (X_test,y_test,name):\n",
    "    count = 0\n",
    "    # 模型测试\n",
    "    for inputs, _ in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = net(inputs)\n",
    "        outputs = np.argmax(outputs.detach().cpu().numpy(), axis=1)\n",
    "        if count == 0:\n",
    "            y_pred =  outputs\n",
    "            count = 1\n",
    "        else:\n",
    "            y_pred = np.concatenate( (y_pred, outputs) )\n",
    "    \n",
    "    if name == 'IP':\n",
    "        target_names = ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn'\n",
    "                          ,'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed', \n",
    "                         'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill',\n",
    "                          'Soybean-clean', 'Wheat', 'Woods', 'Buildings-Grass-Trees-Drives',\n",
    "                          'Stone-Steel-Towers'] \n",
    "    elif name == 'SA':\n",
    "        target_names = ['Brocoli_green_weeds_1','Brocoli_green_weeds_2','Fallow','Fallow_rough_plow','Fallow_smooth',\n",
    "                        'Stubble','Celery','Grapes_untrained','Soil_vinyard_develop','Corn_senesced_green_weeds',\n",
    "                        'Lettuce_romaine_4wk','Lettuce_romaine_5wk','Lettuce_romaine_6wk','Lettuce_romaine_7wk',\n",
    "                        'Vinyard_untrained','Vinyard_vertical_trellis']\n",
    "    elif name == 'PU':\n",
    "        target_names = ['Asphalt','Meadows','Gravel','Trees', 'Painted metal sheets','Bare Soil','Bitumen',\n",
    "                        'Self-Blocking Bricks','Shadows']\n",
    "    elif name == 'KSC':\n",
    "        target_names = ['Water','Mud_flats','Salt_marsh','Catiail_marsh','Spartina_marsh','Graminoid_marsh',\n",
    "                       'Hardwood_swamp','Oak-Broadleaf','Slash_Pine','CP-Oak','CP-hammock','Willow swamp',\n",
    "                       'Scrub']\n",
    "    \n",
    "    classification = classification_report(y_test, y_pred, target_names=target_names)\n",
    "    oa = accuracy_score(y_test, y_pred)\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "    return classification, confusion, oa*100, each_acc*100, aa*100, kappa*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff773e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.38165260879302\n",
      "96.48074037246235\n",
      "95.96450952138488\n"
     ]
    }
   ],
   "source": [
    "classification, confusion, oa, each_acc, aa, kappa = reports(test_loader, ytest, dataset)\n",
    "\n",
    "print(oa)\n",
    "print(aa)\n",
    "print(kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6b96f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1943eab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('XJR')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "126e7dba9e31a2f4e2fdeaa18977348d147742daf45a57e7be21e8fe5c72a0e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
